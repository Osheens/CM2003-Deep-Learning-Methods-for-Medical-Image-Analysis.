{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.gpu.set_per_process_memory_fraction(0.3)\n",
    "tf.config.gpu.set_per_process_memory_growth(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target values are: [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "The predicted values are: [[0.01792371]\n",
      " [0.98329662]\n",
      " [0.98212946]\n",
      " [0.01754808]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logic Operator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "# derivative of Sigmoid function for backprop.\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y, N):\n",
    "        self.input    = x\n",
    "        self.neuron   = N\n",
    "        self.weights1 = np.random.rand(self.input.shape[1], self.neuron) # X dimension input connected to N neurons\n",
    "        self.weights2 = np.random.rand(self.neuron, 1)                   # N neurons connected to output            \n",
    "        self.y        = y\n",
    "        self.output   = np.zeros(self.y.shape)                # instantiating the output\n",
    "\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1)) \n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "\n",
    "    def backprop(self):\n",
    "        # Chain rule to calculate derivative of the loss function with respect to weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T,\n",
    "                            (2*(self.y - self.output)\n",
    "                            * sigmoid_derivative(self.output)))\n",
    "        \n",
    "        d_weights1 = np.dot(self.input.T,\n",
    "                            (np.dot(2*(self.y - self.output)\n",
    "                            * sigmoid_derivative(self.output),\n",
    "                            self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "\n",
    "        # weights updating\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "\n",
    "\n",
    "iterations = 2000\n",
    "n_unit = 10\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    \n",
    "    Input = np.array([[0,0,1],\n",
    "                      [0,1,1],\n",
    "                      [1,0,1],\n",
    "                      [1,1,1]])\n",
    "    \n",
    "    Target = np.array([[0],[1],[1],[0]])\n",
    "               \n",
    "    model = NeuralNetwork(Input, Target, n_unit)\n",
    "    \n",
    "    SSD = []\n",
    "    for i in range(iterations):\n",
    "        model.feedforward()\n",
    "        model.backprop()\n",
    "        errors = (Target - model.output)**2\n",
    "        SSD.append(np.sum(errors))            # Objective(loss) function\n",
    "                      \n",
    "\n",
    "    Itr = np.linspace(1,len(SSD),len(SSD))    \n",
    "    plt.plot(Itr, SSD)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('SSD')\n",
    "\n",
    "    print(\"The target values are:\", Target)\n",
    "    print(\"The predicted values are:\", model.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic operator with Tensorflow Keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "Input = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
    "Target = np.array([[0],[1],[1],[0]], \"float32\")\n",
    "n_unit = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_unit, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer = SGD(),\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(Input, Target, epochs = 5000, verbose=0)\n",
    "\n",
    "print(\"The predicted class labels are:\", model.predict(Input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/io/_io.py:48: UserWarning: `as_grey` has been deprecated in favor of `as_gray`\n",
      "  warn('`as_grey` has been deprecated in favor of `as_gray`')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 0/1000  of train images\n",
      "Reading: 200/1000  of train images\n",
      "Reading: 400/1000  of train images\n",
      "Reading: 600/1000  of train images\n",
      "Reading: 800/1000  of train images\n",
      "Reading: 0/200 of test images\n",
      "Reading: 100/200 of test images\n"
     ]
    }
   ],
   "source": [
    "# Data Loader\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "img_w, img_h = 128, 128                                 # Setting the width and heights of the images\n",
    "data_path = '/Lab1/Skin/'           # Path to data root. Inside this path,\n",
    "                                                        #two subfolder are placed one for train data and one for test data.\n",
    "\n",
    "\n",
    "train_data_path = os.path.join(data_path, 'train')   \n",
    "test_data_path = os.path.join(data_path, 'test')\n",
    "\n",
    "train_list = os.listdir(train_data_path)\n",
    "test_list = os.listdir(test_data_path)\n",
    "\n",
    "# Assigning labels two images; those images contains pattern1 in their filenames\n",
    "# will be labeled as class 0 and those with pattern2 will be labeled as class 1.\n",
    "def gen_labels(im_name, pat1, pat2):\n",
    "        if pat1 in im_name:\n",
    "            Label = np.array([0])\n",
    "        elif pat2 in im_name:\n",
    "            Label = np.array([1])\n",
    "        return Label\n",
    "\n",
    "# reading and resizing the training images with their corresponding labels\n",
    "def train_data(train_data_path, train_list):\n",
    "    train_img = []       \n",
    "    for i in range(len(train_list)):\n",
    "        image_name = train_list[i]\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_grey=True)\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing = True).astype('float32')\n",
    "        train_img.append([np.array(img), gen_labels(image_name, 'Mel', 'Nev')]) \n",
    "        \n",
    "        if i % 200 == 0:\n",
    "             print('Reading: {0}/{1}  of train images'.format(i, len(train_list)))\n",
    "             \n",
    "    shuffle(train_img)\n",
    "    return train_img\n",
    "\n",
    "# reading and resizing the testing images with their corresponding labels\n",
    "def test_data(test_data_path, test_list):\n",
    "    test_img = []       \n",
    "    for i in range(len(test_list)):\n",
    "        image_name = test_list[i]\n",
    "        img = imread(os.path.join(test_data_path, image_name), as_grey=True)\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing = True).astype('float32')\n",
    "        test_img.append([np.array(img), gen_labels(image_name, 'Mel', 'Nev')]) \n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Reading: {0}/{1} of test images'.format(i, len(test_list)))\n",
    "             \n",
    "    shuffle(test_img)   \n",
    "    return test_img\n",
    "\n",
    "# Instantiating images and labels for the model.\n",
    "def get_train_test_data(train_data_path, test_data_path, train_list, test_list):\n",
    "    \n",
    "    Train_data = train_data(train_data_path, train_list)\n",
    "    Test_data = test_data(test_data_path, test_list)\n",
    "       \n",
    "    Train_Img = np.zeros((len(train_list), img_h, img_w), dtype = np.float32)\n",
    "    Test_Img = np.zeros((len(test_list), img_h, img_w), dtype = np.float32)\n",
    "    \n",
    "    Train_Label = np.zeros((len(train_list)), dtype = np.int32)\n",
    "    Test_Label = np.zeros((len(test_list)), dtype = np.int32)\n",
    "    \n",
    "    for i in range(len(train_list)):\n",
    "        Train_Img[i] = Train_data[i][0]\n",
    "        Train_Label[i] = Train_data[i][1]\n",
    "        \n",
    "    Train_Img = np.expand_dims(Train_Img, axis = 3)   \n",
    "    \n",
    "    for j in range(len(test_list)):\n",
    "        Test_Img[j] = Test_data[j][0]\n",
    "        Test_Label[j] = Test_data[j][1]\n",
    "        \n",
    "    Test_Img = np.expand_dims(Test_Img, axis = 3)\n",
    "        \n",
    "    return Train_Img, Test_Img, Train_Label, Test_Label\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_train_test_data(\n",
    "        train_data_path, test_data_path,\n",
    "        train_list, test_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Example; Complete the code\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "n_epochs = 60\n",
    "Batch_Size = 16\n",
    "Base = 64\n",
    "LR = 0.0001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model(img_ch, img_w, img_h):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(img_w, img_h, img_ch)))\n",
    "    model.add(Dense(Base, activation='relu'))\n",
    "    model.add(Dense(Base//2, activation='relu'))\n",
    "    model.add(Dense(Base//4, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "model_MLP=model(1,100,100)\n",
    "model_MLP.compile(loss='binary_crossentropy',optimizer = SGD(LR),metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "History = model_MLP.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size = Batch_Size, epochs= n_epochs, verbose=1)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(History.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(History.history[\"val_loss\"]),\n",
    "         np.min(History.history[\"val_loss\"]),\n",
    "         marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.legend(); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet Model for skin images\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "Base = 8\n",
    "LR = 0.001\n",
    "\n",
    "def model(img_ch, img_width, img_height):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(Base, kernel_size = (3, 3), activation='relu',\n",
    "                     strides=1, padding='same',\n",
    "                     input_shape = (img_width, img_height, img_ch)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(Base*2, kernel_size = (3, 3), activation='relu',\n",
    "                     strides=1, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(Base*2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_LeNet=model(1,100,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "n_epochs = 80\n",
    "Batch_Size = 8\n",
    "\n",
    "model_LeNet.compile(loss='binary_crossentropy',optimizer = Adam(LR),metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "History = model_LeNet.fit(x_train, y_train, batch_size = Batch_Size, epochs= n_epochs, verbose=1, validation_data=(x_test,y_test))\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(History.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(History.history[\"val_loss\"]),\n",
    "         np.min(History.history[\"val_loss\"]),\n",
    "         marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.legend(); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 4)       40        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 128, 4)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 8)         296       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 16)        1168      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 8)         1160      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 140,345\n",
      "Trainable params: 140,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# AlexNet Model for skin images\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "\n",
    "Base = 4\n",
    "LR = 0.01\n",
    "def model(img_ch, img_width, img_height):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=Base, input_shape=(img_width, img_height, img_ch),\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=Base*2, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=Base*4, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters=Base*4, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters=Base*2, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.summary()   \n",
    "    return model\n",
    "model_AlexNet=model(1,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.6939 - binary_accuracy: 0.4910 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.6932 - binary_accuracy: 0.5020 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.6959 - binary_accuracy: 0.4960 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.6934 - binary_accuracy: 0.4990 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.5000 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6937 - binary_accuracy: 0.5140 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6937 - binary_accuracy: 0.4960 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6930 - binary_accuracy: 0.5150 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6942 - binary_accuracy: 0.4710 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.4830 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4990 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - binary_accuracy: 0.4980 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4930 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.4990 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4910 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6931 - binary_accuracy: 0.5030 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 1s 1000us/sample - loss: 0.6930 - binary_accuracy: 0.5060 - val_loss: 0.6933 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6949 - binary_accuracy: 0.4720 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4900 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6939 - binary_accuracy: 0.4720 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.5010 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6936 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.5090 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.5000 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6938 - binary_accuracy: 0.4600 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - binary_accuracy: 0.4830 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.4710 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6930 - binary_accuracy: 0.5070 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.5080 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6938 - binary_accuracy: 0.4850 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - binary_accuracy: 0.4910 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6936 - binary_accuracy: 0.4820 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6936 - binary_accuracy: 0.4740 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6931 - binary_accuracy: 0.5050 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6928 - binary_accuracy: 0.5220 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 1s 998us/sample - loss: 0.6934 - binary_accuracy: 0.5020 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6931 - binary_accuracy: 0.5040 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6938 - binary_accuracy: 0.4820 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6929 - binary_accuracy: 0.5040 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6937 - binary_accuracy: 0.4760 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6931 - binary_accuracy: 0.5020 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.4820 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6936 - binary_accuracy: 0.4850 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6931 - binary_accuracy: 0.5000 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6937 - binary_accuracy: 0.4650 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - binary_accuracy: 0.4960 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4980 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.4850 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 1s 958us/sample - loss: 0.6932 - binary_accuracy: 0.5110 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6936 - binary_accuracy: 0.4700 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6930 - binary_accuracy: 0.5170 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4900 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - binary_accuracy: 0.4880 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4880 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6929 - binary_accuracy: 0.5110 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4870 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 1s 999us/sample - loss: 0.6935 - binary_accuracy: 0.4700 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6936 - binary_accuracy: 0.4580 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.5030 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.4820 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 1s 963us/sample - loss: 0.6932 - binary_accuracy: 0.5020 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6930 - binary_accuracy: 0.4970 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - binary_accuracy: 0.4900 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 1s 993us/sample - loss: 0.6932 - binary_accuracy: 0.4870 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - binary_accuracy: 0.4830 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6929 - binary_accuracy: 0.5150 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.5010 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.4770 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - binary_accuracy: 0.4860 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 1s 958us/sample - loss: 0.6932 - binary_accuracy: 0.4990 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4860 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4890 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.4960 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4890 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6936 - binary_accuracy: 0.4740 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - binary_accuracy: 0.4670 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4930 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 1s 980us/sample - loss: 0.6932 - binary_accuracy: 0.5170 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - binary_accuracy: 0.4980 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6931 - binary_accuracy: 0.4970 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.6933 - binary_accuracy: 0.4860 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4850 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4990 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.5020 - val_loss: 0.6932 - val_binary_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4740 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 1s 952us/sample - loss: 0.6933 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4740 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4720 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4860 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 1s 985us/sample - loss: 0.6931 - binary_accuracy: 0.5080 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4870 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.4920 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.5030 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - binary_accuracy: 0.4690 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 1s 988us/sample - loss: 0.6933 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4930 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6932 - binary_accuracy: 0.5000 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4940 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6933 - binary_accuracy: 0.4760 - val_loss: 0.6931 - val_binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "Batch_Size = 8\n",
    "\n",
    "model_AlexNet.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "History = model_AlexNet.fit(x_train, y_train, batch_size = Batch_Size, epochs= n_epochs, verbose=1, validation_data=(x_test,y_test))\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(History.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(History.history[\"val_loss\"]),\n",
    "         np.min(History.history[\"val_loss\"]),\n",
    "         marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.legend(); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "input_shape = (128, 128, 1)\n",
    "\n",
    "#Instantiate an empty model\n",
    "Base = 8\n",
    "\n",
    "def model(img_ch, img_width, img_height):\n",
    "    \n",
    "    model = Sequential([\n",
    "    Conv2D(Base, (3, 3), input_shape=input_shape, padding='same', activation='relu'),\n",
    "    Conv2D(Base, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(Base*2, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(Base*2, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(Base*4, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*4, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*4, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='softmax')\n",
    "    ])\n",
    "    model.summary()   \n",
    "    return model\n",
    "model_VGG=model(1,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "n_epochs = 50\n",
    "Batch_Size = 8\n",
    "model_VGG.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "History = model_VGG.fit(x_train, y_train, batch_size = Batch_Size, epochs= n_epochs, verbose=1, validation_data=(x_test,y_test))\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(History.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(History.history[\"val_loss\"]),\n",
    "         np.min(History.history[\"val_loss\"]),\n",
    "         marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading bone data\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "img_w, img_h = 128, 128                                 # Setting the width and heights of the images\n",
    "data_path =  '/Lab1/Bone/'\n",
    "           # Path to data root. Inside this path,\n",
    "                                                        #two subfolder are placed one for train data and one for test data.\n",
    "\n",
    "\n",
    "train_data_path = os.path.join(data_path, 'train')   \n",
    "test_data_path = os.path.join(data_path, 'test')\n",
    "\n",
    "train_list = os.listdir(train_data_path)\n",
    "test_list = os.listdir(test_data_path)\n",
    "\n",
    "# Assigning labels two images; those images contains pattern1 in their filenames\n",
    "# will be labeled as class 0 and those with pattern2 will be labeled as class 1.\n",
    "def gen_labels(im_name, pat1, pat2):\n",
    "        if pat1 in im_name:\n",
    "            Label = np.array([0])\n",
    "        elif pat2 in im_name:\n",
    "            Label = np.array([1])\n",
    "        return Label\n",
    "\n",
    "# reading and resizing the training images with their corresponding labels\n",
    "def train_data(train_data_path, train_list):\n",
    "    train_img = []       \n",
    "    for i in range(len(train_list)):\n",
    "        image_name = train_list[i]\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_grey=True)\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing = True).astype('float32')\n",
    "        train_img.append([np.array(img), gen_labels(image_name, 'AFF', 'NFF')]) \n",
    "        \n",
    "        if i % 200 == 0:\n",
    "             print('Reading: {0}/{1}  of train images'.format(i, len(train_list)))\n",
    "             \n",
    "    shuffle(train_img)\n",
    "    return train_img\n",
    "\n",
    "# reading and resizing the testing images with their corresponding labels\n",
    "def test_data(test_data_path, test_list):\n",
    "    test_img = []       \n",
    "    for i in range(len(test_list)):\n",
    "        image_name = test_list[i]\n",
    "        img = imread(os.path.join(test_data_path, image_name), as_grey=True)\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing = True).astype('float32')\n",
    "        test_img.append([np.array(img), gen_labels(image_name, 'AFF', 'NFF')]) \n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Reading: {0}/{1} of test images'.format(i, len(test_list)))\n",
    "             \n",
    "    shuffle(test_img)   \n",
    "    return test_img\n",
    "\n",
    "# Instantiating images and labels for the model.\n",
    "def get_train_test_data(train_data_path, test_data_path, train_list, test_list):\n",
    "    \n",
    "    Train_data = train_data(train_data_path, train_list)\n",
    "    Test_data = test_data(test_data_path, test_list)\n",
    "       \n",
    "    Train_Img = np.zeros((len(train_list), img_h, img_w), dtype = np.float32)\n",
    "    Test_Img = np.zeros((len(test_list), img_h, img_w), dtype = np.float32)\n",
    "    \n",
    "    Train_Label = np.zeros((len(train_list)), dtype = np.int32)\n",
    "    Test_Label = np.zeros((len(test_list)), dtype = np.int32)\n",
    "    \n",
    "    for i in range(len(train_list)):\n",
    "        Train_Img[i] = Train_data[i][0]\n",
    "        Train_Label[i] = Train_data[i][1]\n",
    "        \n",
    "    Train_Img = np.expand_dims(Train_Img, axis = 3)   \n",
    "    \n",
    "    for j in range(len(test_list)):\n",
    "        Test_Img[j] = Test_data[j][0]\n",
    "        Test_Label[j] = Test_data[j][1]\n",
    "        \n",
    "    Test_Img = np.expand_dims(Test_Img, axis = 3)\n",
    "        \n",
    "    return Train_Img, Test_Img, Train_Label, Test_Label\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_train_test_data(\n",
    "        train_data_path, test_data_path,\n",
    "        train_list, test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet Model for bone images\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "Base = 8\n",
    "LR = 0.0001\n",
    "\n",
    "def model(img_ch, img_width, img_height):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(Base, kernel_size = (3, 3), activation='relu',\n",
    "                     strides=1, padding='same',\n",
    "                     input_shape = (img_width, img_height, img_ch)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(Base*2, kernel_size = (3, 3), activation='relu',\n",
    "                     strides=1, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(Base*2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_LeNet=model(1,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "Batch_Size = 8\n",
    "\n",
    "model_LeNet.compile(loss='binary_crossentropy',optimizer = Adam(LR),metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "History = model_LeNet.fit(x_train, y_train, batch_size = Batch_Size, epochs= n_epochs, verbose=1, validation_data=(x_test,y_test))\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(History.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(History.history[\"val_loss\"]),\n",
    "         np.min(History.history[\"val_loss\"]),\n",
    "         marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.legend(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet Model for bone images\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "\n",
    "Base = 8\n",
    "LR = 0.0001\n",
    "def model(img_ch, img_width, img_height):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=Base, input_shape=(img_width, img_height, img_ch),\n",
    "                     kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=Base*2, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=Base*4, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters=Base*4, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(filters=Base*2, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.summary()   \n",
    "    return model\n",
    "model_AlexNet=model(1,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "Batch_Size = 8\n",
    "\n",
    "model_AlexNet.compile(loss='binary_crossentropy',optimizer = Adam(LR),metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "History = model_AlexNet.fit(x_train, y_train, batch_size = Batch_Size, epochs= n_epochs, verbose=1, validation_data=(x_test,y_test))\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(History.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(History.history[\"val_loss\"]),\n",
    "         np.min(History.history[\"val_loss\"]),\n",
    "         marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.legend(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG for bone images\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "input_shape = (128, 128, 1)\n",
    "\n",
    "#Instantiate an empty model\n",
    "Base = 8\n",
    "\n",
    "def model(img_ch, img_width, img_height):\n",
    "    \n",
    "    model = Sequential([\n",
    "    Conv2D(Base, (3, 3), input_shape=input_shape, padding='same', activation='relu'),\n",
    "    Conv2D(Base, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(Base*2, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(Base*2, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(Base*4, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*4, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*4, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(Base*8, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='softmax')\n",
    "    ])\n",
    "    model.summary()   \n",
    "    return model\n",
    "model_VGG=model(1,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "n_epochs = 50\n",
    "Batch_Size = 8\n",
    "model_VGG.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "History = model_VGG.fit(x_train, y_train, batch_size = Batch_Size, epochs= n_epochs, verbose=1, validation_data=(x_test,y_test))\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(History.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(History.history[\"val_loss\"]),\n",
    "         np.min(History.history[\"val_loss\"]),\n",
    "         marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
